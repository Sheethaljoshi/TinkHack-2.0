{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (1.23.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install openai\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "file1 = client.files.create(\n",
    "  file=open(\"doc.pdf\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"key_topics\": \"1. [Unique Blend of Traits]: Sheethal's introspection and bubbly charm merge uniquely.\\n2. [Cultural Adaptation]: Sheethal's worldview shaped by living in nine countries.\\n3. [Contrasting Environments]: Transition from New York fast pace to Kerala serenity.\\n4. [Culinary Influences]: Her diverse experiences are reflected in eclectic tastes.\\n5. [Passion for Reading]: Sheethal is deeply immersed in fantasy novels.\\n6. [Tech Industry Challenges]: Introspection clashes with fast-paced tech demands.\\n7. [Significance of Colors]: Purple and pink embody creativity and contemplation.\\n8. [Nicknames and Social Circle]: \\\"Sheep\\\" or \\\"Sheethu\\\" reflects her warm connections.\\n9. [Personality Dynamics]: Introversion tempered by moments of bubbly, joyful interactions.\\n10. [Journey of Harmony]: Navigating life by embracing contradictions and chaos.\",\n",
      "    \"image_url\": \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-k8NvQfLGW5lThbQ4AHXIROAM/user-HGRHKZbnGonRpZxSjqG80fFI/img-0s6cRqV0f0wwfF2IWrwDxEvR.png?st=2025-03-22T19%3A18%3A40Z&se=2025-03-22T21%3A18%3A40Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-03-22T13%3A47%3A30Z&ske=2025-03-23T13%3A47%3A30Z&sks=b&skv=2024-08-04&sig=gRnYpGt%2BJLpBAOMWFgW0sJvXrNTj8vMTRQXgntES9hw%3D\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a given PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            extracted = page.extract_text()\n",
    "            if extracted:  # Ensure text is not None\n",
    "                text += extracted + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def generate_key_topics_and_image(pdf_path):\n",
    "    \"\"\"Generates key topics and an image URL based on PDF content.\"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # Extract text from PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Generate key topics using GPT-4o\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts key learning points from text.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze the following text and extract the key topics to be learned from it. \"\n",
    "                                            \"Present them in a numbered list with each point in the following format:\\n\\n\"\n",
    "                                            \"[Topic Name]: A concise description (max 10 words) of its relevance or importance.\\n\\n\"\n",
    "                                            \"Ensure the topics cover all major aspects of the text and are arranged logically.\\n\\n\"\n",
    "                                            f\"Text:\\n{pdf_text}\"}\n",
    "        ]\n",
    "    )\n",
    "    key_topics = completion.choices[0].message.content\n",
    "    \n",
    "    # Generate an image using DALLÂ·E 3\n",
    "    image_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"An artistic representation of the main themes in the following text: {pdf_text[:1000]}\",\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    \n",
    "    image_url = image_response.data[0].url\n",
    "    \n",
    "    return json.dumps({\"key_topics\": key_topics, \"image_url\": image_url}, indent=4)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":  # Replace with your actual OpenAI API key\n",
    "    PDF_PATH = \"people.pdf\"  # Replace with the path to your PDF\n",
    "    \n",
    "    result_json = generate_key_topics_and_image(PDF_PATH)\n",
    "    \n",
    "    print(result_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-sJvUxxLYbwS7B4LXpbWaCqb4', bytes=28856, created_at=1714827778, filename='doc.pdf', object='file', purpose='assistants', status='processed', status_details=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = client.beta.vector_stores.create(\n",
    "  name=\"Support FAQ\",\n",
    "  file_ids= [file1.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vs_l7uuSAnirZgPKhfnSriaOoTu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "file2 = client.files.create(\n",
    "  file=open(\"people.pdf\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-94FBwLqtKCAnqkr7nf4Egw'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vector_store_file = client.beta.vector_stores.files.create(\n",
    "  vector_store_id='vs_67d542ae493881918be2d7418d8d7b57' ,\n",
    "  file_id= 'file-94FBwLqtKCAnqkr7nf4Egw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-94FBwLqtKCAnqkr7nf4Egw', created_at=1742029863, last_error=None, object='vector_store.file', status='completed', vector_store_id='vs_67d542ae493881918be2d7418d8d7b57', usage_bytes=2949, chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}, attributes={})], object='list', first_id='file-94FBwLqtKCAnqkr7nf4Egw', last_id='file-94FBwLqtKCAnqkr7nf4Egw', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "vector_store_files = client.beta.vector_stores.files.list(\n",
    "  vector_store_id='vs_67d542ae493881918be2d7418d8d7b57' \n",
    ")\n",
    "print(vector_store_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_67d542ae493881918be2d7418d8d7b57', bytes=None, created_at=1742029486, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1742029486, metadata={}, name='Support FAQ', object='vector_store', status='completed', expires_after=None, expires_at=None, usage_bytes=0)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(\n",
    "  name=\"Support FAQ\"\n",
    ")\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 + 2 equals 5.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[ {\"role\": \"system\" , \"content\":\"you are a teacher\"},{\"role\": \"user\", \"content\": \"What is 3+2?\"}\n",
    "           ,],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (464676131.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "deleted_vector_store_file = client.beta.vector_stores.files.delete(\n",
    "    vector_store_id='vs_67d542ae493881918be2d7418d8d7b57' ,\n",
    "    file_id=\"file-iGmWicUuoqEfymsw3Zfjif1p\"\n",
    ")\n",
    "print(deleted_vector_store_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-A7M93WRkLSJS64SMtHnhSZ', created_at=1742128343, last_error=None, object='vector_store.file', status='completed', vector_store_id='vs_67d542ae493881918be2d7418d8d7b57', usage_bytes=3054, chunking_strategy={'type': 'static', 'static': {'max_chunk_size_tokens': 800, 'chunk_overlap_tokens': 400}}, attributes={})], object='list', first_id='file-A7M93WRkLSJS64SMtHnhSZ', last_id='file-A7M93WRkLSJS64SMtHnhSZ', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "vector_store_files = client.beta.vector_stores.files.list(\n",
    "  vector_store_id='vs_67d542ae493881918be2d7418d8d7b57' \n",
    ")\n",
    "print(vector_store_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is pink, as you mentioned your love for wearing your \"favorite pink eyeshadow\"ã5:0â sourceã.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_answer(question):\n",
    "    # Your OpenAI Assistant logic here\n",
    "    client = OpenAI()\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Personal Helper\",\n",
    "        instructions=\"The person asking questions is Sheethal Joshi\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=[{\"type\": \"file_search\"}],\n",
    "    )\n",
    "\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": ['vs_67d542ae493881918be2d7418d8d7b57' ]}},\n",
    "    )\n",
    "\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Answer the following questions from the data files provided, keeping in mind that the user is Sheethal Joshi. She talks in first person. \"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions= question,\n",
    "    )\n",
    "\n",
    "    if run.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        answer = messages.data[0].content[0].text.value\n",
    "        return answer\n",
    "\n",
    "return_answer(\"What is my favourite colour?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment\n\u001b[1;32m---> 19\u001b[0m yes \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLife feels like an endless cycle of disappointments, where every effort seems pointless, and nothing ever goes right. The world is a bleak, unforgiving place filled with stress, failure, and endless frustration. No matter how hard one tries, setbacks and misfortune always seem to lurk around the corner, ready to crush any fleeting sense of hope. People are unreliable, opportunities are scarce, and happiness feels like an illusion that fades the moment you reach for it. Every day is just another struggle, weighed down by exhaustion, regret, and the constant realization that things will probably never get better.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mget_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentiment\u001b[39m(text):\n\u001b[0;32m      5\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSentiment analysis of the following text:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_utils\\_utils.py:276\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=f\"Sentiment analysis of the following text:\\n{text}\\n\",\n",
    "        temperature=0.5,\n",
    "        max_tokens=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=[\"\\n\"]\n",
    "    )\n",
    "\n",
    "    sentiment = response.choices[0].text.strip()\n",
    "    return sentiment\n",
    "yes = get_sentiment(\"Life feels like an endless cycle of disappointments, where every effort seems pointless, and nothing ever goes right. The world is a bleak, unforgiving place filled with stress, failure, and endless frustration. No matter how hard one tries, setbacks and misfortune always seem to lurk around the corner, ready to crush any fleeting sense of hope. People are unreliable, opportunities are scarce, and happiness feels like an illusion that fades the moment you reach for it. Every day is just another struggle, weighed down by exhaustion, regret, and the constant realization that things will probably never get better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiments: [('negative',)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"I love this!\", \n",
    "        \"This is so frustrating and annoying.\", \n",
    "        \"I'm happy but also a bit disappointed.\",\n",
    "        \"What a terrible experience!\",\n",
    "        \"Absolutely amazing, I feel great!\",\n",
    "        \"I'm feeling really anxious and worried.\",  # New sentence\n",
    "        \"That dark alley made me very nervous.\"    # New sentence\n",
    "    ],\n",
    "    \"labels\": [\n",
    "        [\"positive\"], \n",
    "        [\"negative\", \"anger\"], \n",
    "        [\"positive\", \"negative\"], \n",
    "        [\"negative\"], \n",
    "        [\"positive\", \"joy\"], \n",
    "        [\"fear\"],  # New label\n",
    "        [\"fear\"]   # New label\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Convert labels into binary format\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data[\"labels\"])\n",
    "\n",
    "# Create a text processing & classification pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  \n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))  \n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(data[\"text\"], y)\n",
    "\n",
    "# Example prediction\n",
    "test_text = [\"I'm so excited but also a bit nervous.\"]\n",
    "pred = pipeline.predict(test_text)\n",
    "\n",
    "# Convert prediction back to labels\n",
    "predicted_labels = mlb.inverse_transform(pred)\n",
    "print(\"Predicted Sentiments:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai = 65365d3afc6b45209b1f29bc0c9dd298\n",
    "\n",
    "11 = sk_3e7882bbdb11d9a4b0627ed68042bb9aec0ef171ccf2b4a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
